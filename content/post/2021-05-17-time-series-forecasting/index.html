---
title: Time series forecasting
author: ''
date: '2021-05-17'
slug: time-series-forecasting
categories: []
tags: []
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<pre class="r"><code>library(crypto)
library(RGENERATE)
library(quantmod)
library(lubridate)
library(tseries)
library(tidyverse)
library(forecast)

times &lt;- RGENERATE::generate(FUN = rnorm, n = 1000, K = 3,names = c(&quot;asset1&quot;)) %&gt;% 
  mutate(price = cumsum(asset1)+300) %&gt;%
  mutate(day = row_number())

times %&gt;% 
  ggplot(aes(day, price))+
  geom_line()+theme_minimal() +
  geom_smooth(method = &#39;lm&#39;, lty = 2, colour = &#39;red&#39;, se = F)+
  labs(title = &quot;Dynamically created time series&quot;,
       subtitle = &quot;Created using the RGENERATE pakage&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<div id="arima-modelling-assumptions" class="section level1">
<h1>ARIMA modelling assumptions</h1>
<p><span class="math display">\[X_t = c + \epsilon_t + \sum_{i=1}^p\beta_iX_{t-i}+\sum_{i=1}^q\theta_i\epsilon_{t-i}\]</span></p>
<ol style="list-style-type: decimal">
<li><p>An ARIMA model is a regression combining an autoregression with integration and a moving average.</p></li>
<li><p>For example, an ARIMA(3, 2, 5) model refers to a model with 3 autoregressive terms like <span class="math inline">\(X_t = \beta_1X_{t-1}+\ldots+\beta_3X_{t-3}+\ldots\)</span>, 2 orders of differencing to remove non-stationarity, and 5 moving average terms <span class="math inline">\(X_t=\ldots+\theta_{1} \epsilon_{t-1}+\ldots+\theta_5\epsilon_{t-5}\)</span></p></li>
<li><p>We should be able to test to see which is the optimal number of terms to use for our model to aid in predictive power.</p></li>
<li><p>The ARIMA model assumes that the data is univariate, that is it assumes there is only one explanatory variable, that being the previous consecutive price point.</p></li>
<li><p>It also assumes the data to be stationary, that is the error term <span class="math inline">\(\epsilon_t\)</span> is normally distributed and considered to be ‘white-noise’.</p></li>
</ol>
<div id="augmented-dickey-fuller-test" class="section level3">
<h3>Augmented Dickey-Fuller test</h3>
<p>The Dickey-Fuller test checks to see if the time series is stationary. It is possible to simply plot the residuals of the data and then ‘eyeball’ it to see if the error terms largely tend towards zero and are normally distributed, that is <span class="math inline">\(\epsilon_t\)</span> ~ <span class="math inline">\(\\N(0, \sigma^2)\)</span>. Otherwise…</p>
<p><span class="math display">\[\Delta y_t=c+\beta t + \gamma y_{t-1} + \sum_{i = 1}^{p}\delta\Delta y_{t-i} + e_t\]</span> where <span class="math inline">\(c =\)</span> regression constant. <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\gamma\)</span>, <span class="math inline">\(\delta_i\)</span> are regression coefficients. <span class="math inline">\(p =\)</span> number of lagged terms. The Dickey-Fuller test tests for significance of the <span class="math inline">\(\gamma\)</span> coefficient with the null hypothesis <span class="math inline">\(H_0 : \gamma = 1\)</span>, meaning that the lag coefficient is significant therefore the time series is non-stationary against <span class="math inline">\(H_1:\gamma \neq1\)</span>, meaning that the lag variable coefficient is insignificant and that the model exhibits stationarity.</p>
<pre class="r"><code>(adf_output &lt;- adf.test(times$price))</code></pre>
<pre><code>## 
##  Augmented Dickey-Fuller Test
## 
## data:  times$price
## Dickey-Fuller = -1.8879, Lag order = 9, p-value = 0.6258
## alternative hypothesis: stationary</code></pre>
<pre class="r"><code>adf_output$p.value</code></pre>
<pre><code>## [1] 0.6257587</code></pre>
<pre class="r"><code>adf_output$significant &lt;- ifelse(adf_output$p.value&lt;0.05,&quot;significant&quot;,&quot;insignificant&quot;)</code></pre>
<p>The p value of 0.63 is insignificant which allows us to infer that our time series data exhibits non-stationarity as the lag variable has a significant coefficient. We are unable to reject the null hypothesis that the coefficient is equal to 1.</p>
<p>In the case of non-stationarity, there are a few options to coerce stationarity such as taking the log or the square roots of the data to stabalise non-constant variance, calculating the residuals from another fitted model, or simply taking another difference of our series data, that is <span class="math inline">\(\Delta^2\)</span>.</p>
<p>This can be demonstrated as follows</p>
<pre class="r"><code>times &lt;- times %&gt;% 
  mutate(diff_price = price - lag(price)) %&gt;% 
  filter(!is.na(diff_price))

times %&gt;% ggplot(aes(day, diff_price)) + geom_line()+
  geom_smooth(method = &#39;lm&#39;, lty = 2, colour = &#39;red&#39;, se = F)+
  theme_void()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>ts(times$diff_price, start = c(2000,1), frequency = 365) %&gt;% 
  decompose()%&gt;% 
  plot()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<pre class="r"><code>adf.test(times$diff_price)</code></pre>
<pre><code>## 
##  Augmented Dickey-Fuller Test
## 
## data:  times$diff_price
## Dickey-Fuller = -9.8596, Lag order = 9, p-value = 0.01
## alternative hypothesis: stationary</code></pre>
<p>Many other unit root tests exist such as the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test.</p>
<p>Alternatively, seasonality can be removed from the time series data using the in-built R stats functions.</p>
<pre class="r"><code>times.decomposed &lt;- ts(times$price, start = c(2000,1), frequency = 365) %&gt;% 
  decompose()
times.season.adj &lt;- times$price - times.decomposed$seasonal

times.season.adj.test &lt;- diff(times.season.adj, differences = 1)

plot(times.season.adj.test)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
</div>
<div id="fitting-the-model" class="section level1">
<h1>Fitting the model</h1>
<p>There are options to choose from for how we estimate the accuracy of our model. Namely, ML = Maximum Likelihood estimation, AIC = <a href="https://www.scribbr.com/statistics/akaike-information-criterion/">Akaike Information Criterion</a>,</p>
<pre class="r"><code>acf(times$price, lag.max=70)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>fitARIMA &lt;- arima(times$price, order=c(1,1,1),seasonal = list(order = c(1,0,0), period = 12),method=&quot;ML&quot;)


confint(fitARIMA)</code></pre>
<pre><code>##            2.5 %    97.5 %
## ar1          NaN       NaN
## ma1          NaN       NaN
## sar1 -0.01910548 0.1051607</code></pre>
<p>Instead of going through each iteration of Arima(x, y, z) and selecting the best model, we can use the auto.arima() function in R from the forecasts package.</p>
<pre class="r"><code>times.arima_auto_model &lt;- auto.arima(times$price %&gt;% log(), trace = TRUE)</code></pre>
<pre><code>## 
##  Fitting models using approximations to speed things up...
## 
##  ARIMA(2,1,2) with drift         : -8324.657
##  ARIMA(0,1,0) with drift         : -8328.556
##  ARIMA(1,1,0) with drift         : -8325.609
##  ARIMA(0,1,1) with drift         : -8326.561
##  ARIMA(0,1,0)                    : -8330.367
##  ARIMA(1,1,1) with drift         : -8323.594
## 
##  Now re-fitting the best model(s) without approximations...
## 
##  ARIMA(0,1,0)                    : -8341.565
## 
##  Best model: ARIMA(0,1,0)</code></pre>
</div>
<div id="forecasting-with-the-arima-model" class="section level1">
<h1>Forecasting with the Arima model</h1>
<pre class="r"><code>times.predictions &lt;- forecast::forecast(object = times$price %&gt;% log(), model = times.arima_auto_model, h = 30)




times.predictions %&gt;% plot()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>times.predictions &lt;- as.tibble(times.predictions)



cbind(times.predictions, day = 1:nrow(times.predictions)+999) %&gt;% 
  ggplot(aes(day, times.predictions$`Point Forecast`))+
  geom_ribbon(aes(ymin = `Lo 95`, ymax = `Hi 95`), alpha = 0.2, colour = &quot;black&quot;, fill = &quot;dodgerblue&quot;)+
  geom_ribbon(aes(ymin = `Lo 80`, ymax = `Hi 80`), alpha = 0.2, colour = &quot;black&quot;, fill = &quot;blue&quot;)+
  theme_minimal()+
  geom_line(lty = 2)+
  labs(title = &quot;Forecasting asset price with the Arima model&quot;,
       subtitle = &quot;A 60 day forecast - 95% and 80% confidence intervals&quot;,
       y = &quot;price&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
</div>
<div id="forecasting-real-world-price-data" class="section level1">
<h1>Forecasting real-world price data</h1>
<div id="tesla" class="section level3">
<h3>Tesla</h3>
<pre class="r"><code>#btc &lt;- read_csv(&quot;btc.csv&quot;)

quantmod::getSymbols(&quot;TSLA&quot;)</code></pre>
<pre><code>## [1] &quot;TSLA&quot;</code></pre>
<pre class="r"><code>tsla_model &lt;- log(TSLA$TSLA.Close) %&gt;% auto.arima(trace = TRUE, stationary = FALSE)</code></pre>
<pre><code>## 
##  Fitting models using approximations to speed things up...
## 
##  ARIMA(2,1,2) with drift         : -10588.87
##  ARIMA(0,1,0) with drift         : -10559.17
##  ARIMA(1,1,0) with drift         : -10556.19
##  ARIMA(0,1,1) with drift         : -10557.18
##  ARIMA(0,1,0)                    : -10554.44
##  ARIMA(1,1,2) with drift         : Inf
##  ARIMA(2,1,1) with drift         : -10572.54
##  ARIMA(3,1,2) with drift         : -10588.01
##  ARIMA(2,1,3) with drift         : -10588.29
##  ARIMA(1,1,1) with drift         : Inf
##  ARIMA(1,1,3) with drift         : -10550.88
##  ARIMA(3,1,1) with drift         : -10581.34
##  ARIMA(3,1,3) with drift         : Inf
##  ARIMA(2,1,2)                    : -10582.86
## 
##  Now re-fitting the best model(s) without approximations...
## 
##  ARIMA(2,1,2) with drift         : -10562.93
## 
##  Best model: ARIMA(2,1,2) with drift</code></pre>
<pre class="r"><code>tsla_forecast &lt;- forecast::forecast(object = TSLA$TSLA.Close, model = tsla_model, h = 60)



forecast(tsla_model, h = 70) %&gt;% plot()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="amazon" class="section level3">
<h3>Amazon</h3>
<pre class="r"><code>quantmod::getSymbols(&quot;AMZN&quot;)</code></pre>
<pre><code>## [1] &quot;AMZN&quot;</code></pre>
<pre class="r"><code>AMZN_model &lt;- log(AMZN$AMZN.Close) %&gt;% auto.arima(trace = TRUE, stationary = FALSE)</code></pre>
<pre><code>## 
##  Fitting models using approximations to speed things up...
## 
##  ARIMA(2,1,2) with drift         : -16841.78
##  ARIMA(0,1,0) with drift         : -16839.48
##  ARIMA(1,1,0) with drift         : -16839.27
##  ARIMA(0,1,1) with drift         : -16840.53
##  ARIMA(0,1,0)                    : -16831.92
##  ARIMA(1,1,2) with drift         : -16844.08
##  ARIMA(0,1,2) with drift         : -16847.08
##  ARIMA(0,1,3) with drift         : -16845.07
##  ARIMA(1,1,1) with drift         : -16842.87
##  ARIMA(1,1,3) with drift         : Inf
##  ARIMA(0,1,2)                    : -16837.88
## 
##  Now re-fitting the best model(s) without approximations...
## 
##  ARIMA(0,1,2) with drift         : -16854.55
## 
##  Best model: ARIMA(0,1,2) with drift</code></pre>
<pre class="r"><code>AMZN_forecast &lt;- forecast::forecast(object = AMZN$AMZN.Close, model = AMZN_model, h = 70)


forecast(AMZN_model, h = 70) %&gt;% plot()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
</div>
