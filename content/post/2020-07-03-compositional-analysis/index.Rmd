---
title: 'Metallurgical compositional analysis'
author: ''
date: '2020-07-03'
slug: compositional-analysis
categories: []
tags: []
---

```{r setup, include=FALSE, message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = T,warning = FALSE, message = FALSE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
library(compositions)
library(readr)
library(mgcv)
library(tidyverse)
library(neuralnet)
library(caret)
library(caretEnsemble)
library(httr)
library(readxl)
```

```{r}
divide01 <- function(x){
  return(x/100)
}

data <- read.csv("hardness.csv") %>% 
  mutate(Al=divide01(Al),
         Co=divide01(Co),
         Cr=divide01(Cr),
         Cu=divide01(Cu),
         Fe=divide01(Fe),
         Ni=divide01(Ni))
data_ordered <- read.csv("hardness.csv") %>% 
  mutate(Al=divide01(Al),
         Co=divide01(Co),
         Cr=divide01(Cr),
         Cu=divide01(Cu),
         Fe=divide01(Fe),
         Ni=divide01(Ni)) %>% 
  arrange(desc(hardness))

closed <- clo(data, parts = 1:6,total=100)
cx <- acomp(data, c("Al","Co","Cr"))
plot(cx)
xc <- acomp(data, c("Al","Co","Cr","Cu","Fe","Ni"))
xc_ordered <- acomp(data_ordered, c("Al","Co","Cr","Cu","Fe","Ni"))
plot(xc)
barplot.acomp(xc)

```

Order of hardness desc



```{r}

barplot.acomp(xc_ordered)
         
```

Possibly drop copper and nickel


```{r}
library(httr)
raw_dd <- read.table(text=content(GET("https://gist.githubusercontent.com/MrFlick/c1183c911bc5398105d4/raw/715868fba2d0d17a61a8081de17c468bbc525ab1/elements.txt")), sep=",", header=TRUE) %>%
  mutate(ElementName=ifelse(ElementName=="Sulfer","Sulfur",ElementName),
         ElementName=ifelse(ElementName=="Phosphorous","Phosphorus",ElementName),
         ElementName=ifelse(ElementName=="Flourine","Fluorine",ElementName))
data <- read_xlsx("melting_points.xlsx", sheet = 'Sheet2')
colnames(raw_dd) <- c(colnames(raw_dd)[1:7],"element",colnames(raw_dd)[9:13])
```


```{r}
dd <- raw_dd %>%
  left_join(data, by = "element") %>%
  mutate(CTE_ppm=CTE*1000000,
         CTE_ppm=as.numeric(CTE_ppm),
         scaled_cte=CTE_ppm,
         scaled_cte=ifelse(scaled_cte>8,8,scaled_cte),
         scaled_cte=ifelse(scaled_cte<4.5,4.4,scaled_cte),
         new_structure=ifelse(crystal_structure %in% c("Body-centered Cubic","Face-centered Cubic","Simple Hexagonal"),crystal_structure,NA))
```


```{r}
dd %>%
  ggplot(aes(Column,-Row)) +
  geom_tile(aes(fill=crystal_structure), color="black") +
  geom_text(aes(Column, -Row,label= symbol))+
  theme_void()+
  labs(
    fill = "Crystal Structure"
  ) +
  annotate("text", x = 7, y = 0.2, label = "Periodic Table of the elements", size = 5)
```

```{r}
(p<-dd %>%
  filter(!is.na(symbol)) %>%
  #filter(!crystal_structure %in% c("Base-centered Monoclinic","Centered Tetragonal")) %>%
  ggplot(aes(Column, -Row))+
  geom_tile(aes(fill=scaled_cte), color="black",size=1) +
  geom_rect(aes(xmin=Column-0.3,xmax=Column+0.3,ymin=-Row-0.2,ymax=-Row+0.3,colour=new_structure),size=1,lty=1,fill="black")+
    #geom_text(aes(label="",colour=new_structure), na.rm = T,size=12,nudge_y = 0.3)+
  geom_text(aes(label=symbol),colour="yellow",nudge_y = +0.05)+
  geom_text(aes(label=CTE_ppm),colour="black",nudge_y = -0.35)+
  scale_fill_gradient(low = "red",high = "green")+
  labs(fill = expression(paste("CTE", 10^6)),
    colour="") +
  annotate("text", x = 7, y = 0.2, label = "Periodic Table of the elements", size = 5))+
  theme_void()+
  theme(legend.position="bottom")+
  scale_colour_discrete(na.translate = F)


```



```{r}

f1 <- function(x){
  return(1/(16.6*3*(x+273)))
}

library(plotly)
library(ggrepel)
data %>% 
  ggplot(aes(mp, CTE, label=element))+
  geom_point()+
  stat_function(fun=f1)+
  lims(
    x=c(1500,4000),
    y=c(0,0.000025)
  )+
  theme(legend.position = "none")+
  ggrepel::geom_text_repel()+
  theme_classic()


```

# Predictive modelling

Compositional data can be transformed to satisfy linearity by using logratio transformations for representation in a Euclidean space. Additive, isometric, and centre logratio transformations are available.  

The transformations give the same coefficients for the multi-variate regressions so we will stick with the additive logratio defined as: $$alr(x) = \left [\log\frac{x_1}{x_n},\ldots,\log\frac{x_{n-1}}{x_n}\right]$$

These transformation functions are available within the 'compositions' R package. Ratio transformations have issues with zero-value elements.

PRINCIPLES OF COMPOSITIONAL DATA ANALYSIS
BY JOHN AITCHISON


```{r}
library(compositions)

library(caret)

library(glmnet)
hard <- read_csv("hardness.csv")
#hard %>% arrange(-hardness)
```


```{r}
# Filtering out zero values for logratio transformations
hard_ <- hard %>% 
  #filter(Al > 0, Co > 0, Cr > 0, Cu > 0, Fe > 0, Ni > 0)
   mutate(Al = ifelse(Al == 0, 1, Al),
          Co = ifelse(Co == 0, 1, Co),
          Cr = ifelse(Cr == 0, 1, Cr),
          Cu = ifelse(Cu == 0, 1, Cu),
          Fe = ifelse(Fe == 0, 1, Fe),
          Ni = ifelse(Ni == 0, 1, Ni))


```


```{r}
# Setting x, y


y <- hard_$hardness
x <- hard_[,1:ncol(hard)-1]
```


```{r}
hard.clr <- x %>% 
  clr()
hard.ilr <- x %>% 
  ilr()
hard.alr <- x %>% 
  alr()

```


```{r}
#predict(hard.clr.lm,clr(v))

hard.clr.lm <- lm(y ~ ., cbind(y,hard.clr) %>% data.frame())
hard.ilr.lm <- lm(y ~ ., cbind(y,hard.ilr) %>% data.frame())
hard.alr.lm <- lm(y ~ ., cbind(y,hard.alr) %>% data.frame())
```


```{r}
hard.ilr.glm.model <- cv.glmnet(hard.ilr, y, alpha = 1)
hard.ilr.glm <- glmnet(hard.ilr, y, alpha = 1, lambda = hard.ilr.glm.model$lambda.min)
```


```{r}
dataset <- cbind(data.frame(hardness = y),hard.clr) %>% data.frame()

hard.clr.gam <- gam(hardness ~ Al+ Co + Co + Cr + Cu + Fe + Ni, data = dataset)
```


```{r}
predictions.full <- data.frame(hard_) %>% 
  mutate(prediction.clr.lm = predict(hard.clr.lm, newx = hard_),
         prediction.ilr.lm = predict(hard.ilr.lm, newx = hard.ilr),
         #prediction.alr.lm = predict(hard.alr.lm, newx = hard.alr),
         prediction.ilr.glm = predict(hard.ilr.glm, best_lambda = hard.ilr.glm.model$lambda.min, newx = hard.ilr),
         prediction.clr.gam = predict(hard.clr.gam, newx = hard.clr),
         pre = predict(hard.clr.lm, newx = row()))
```


```{r}
# predictions.full %>% colnames

predictions.full %>% 
  arrange(hardness) %>% 
  mutate(row_name = row_number()) %>% 
  pivot_longer(c(hardness, prediction.clr.lm,prediction.ilr.glm, prediction.clr.gam), names_to = "variable",values_to = "value") %>% 
  ggplot(aes(row_name, value, colour = variable, shape = variable))+
  geom_point(alpha = 0.8)+
  labs(title = "Hardness prediction",
       subtitle = "Comparing hardness prediction.clr.lm and actual hardness",
       y = "hardness",
       x = "rank ordered by ascending hardness")+
  #annotate("text", y = 200, x = 25,label = paste("RMSE = ",
   # round(RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness),2)
  #))+
  theme_bw()+
  theme(legend.position = c(0.8,0.2),
        legend.background = element_rect(fill = "white", color = "black"))+
  scale_color_discrete(name = paste("RMSE = ", round(RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness),2)))+
  scale_shape_discrete(name = paste("RMSE = ", round(RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness),2)))
   
```


```{r}

  

# Linear regression on ILR logratio transformation  
RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness)

# Lasso regression on ILR logratio transformation
RMSE(predictions.full$prediction.ilr.glm, predictions.full$hardness)

# generalised additive model
RMSE(predictions.full$prediction.clr.gam, predictions.full$hardness)

# library(robCompositions)
# aDist(x = hard_[,1:ncol(hard)-1])
#Compositional::alfa.ridge(as.matrix(y), as.matrix(x),a = 0.01, lambda = 1)




```


# Principal component analysis for compositional data vectors
https://link.springer.com/article/10.1007/s00180-015-0570-1


# Artificial Neural Network (ANN) approach


```{r}
scale01 <- function(x){
  (x - min(x)) / (max(x) - min(x))
}


scale02 <- function(y){
  y * (max(hard_$hardness) - min(hard_$hardness)) + min(hard_$hardness)
}



hard_ann <- cbind(hard_$hardness,as.tibble(hard.clr)) %>% 
  mutate_all(scale01) %>% rename("hardness" = "hard_$hardness")


set.seed(123)
hard_ann_train <- sample_frac(tbl = hard_ann, replace = FALSE, size = 0.80)
hard_ann_test <- anti_join(hard_ann, hard_ann_train)
```


```{r}
hard_ann_model1 <- neuralnet(hardness ~ Al + Co + 
                         Cr + Cu + Fe +
                         Ni, data = hard_ann_train)
```


```{r}
hard_ann_model2 <- neuralnet(hardness ~ Al + Co + 
                         Cr + Cu + Fe +
                         Ni, data = hard_ann_train,
                         hidden = c(4, 1), 
                         act.fct = 'logistic',
                         rep = 10)

```



```{r}
hard_ann_test_output1 <- compute(hard_ann_model1, hard_ann_test[, 2:7])$net.result
hard_ann_test_output2 <- compute(hard_ann_model2, hard_ann_test[, 2:7])$net.result


hard_ann_sse1 <- sum((hard_ann_test_output1 - hard_ann_test[, 1])^2)/2
hard_ann_sse2 <- sum((hard_ann_test_output2 - hard_ann_test[, 1])^2)/2


hard_ann_sse1
hard_ann_sse2 # model 2 is more accurate




dat <- cbind(p = hard_ann_test_output2, hard_ann_test) %>%
  arrange(hardness) %>%
  mutate(row = row_number()) %>% 
  mutate(prediction = scale02(p),
         hardness = scale02(hardness))


dat
dat %>% 
  pivot_longer(c("prediction","hardness")) %>% 
  mutate(row = as.integer((row_number()-1)/2)) %>% 
  ggplot(aes(row, value, colour = name, shape = name)) + 
  geom_point()+
  scale_color_discrete(name = paste("RMSE = ", round(RMSE(dat$prediction,dat$hardness),2)))+
  scale_shape_discrete(name = paste("RMSE = ", round(RMSE(dat$prediction,dat$hardness),2)))+
  labs(title = "Unseen data observations ANN",
       subtitle = "Comparing hardness artificial neural network regression and actual hardness on unseen data")+
  theme_bw()+
  theme(legend.position = c(0.8,0.2),
        legend.background = element_rect(fill = "white", color = "black"))



```

```{r}
hard_ann_results <- compute(hard_ann_model2, hard_ann[, 2:7])$net.result
```


```{r}
dat <- cbind(predictions = hard_ann_results, hard_ann) %>% 
  mutate("ANN prediction" = scale02(predictions),
         hardness = scale02(hardness)) %>% 
  arrange(hardness) %>% 
  pivot_longer(c("ANN prediction","hardness"), values_to = "val", names_to = "var") %>% 
  mutate(row = as.integer((row_number()-1)/2))




g <- cbind(data.frame(p = hard_ann_results) %>% mutate(p = scale02(p)),hard_ann) %>% 
  mutate(hardness = scale02(hardness))

dat %>% 
  ggplot(aes(row, val, shape = var, colour = var)) +
  geom_point()+
  scale_color_discrete(type = c("dodgerblue", "red"),name = paste("RMSE = ",round(RMSE(g$p, g$hardness),2)))+
  scale_shape_discrete(name = paste("RMSE = ",round(RMSE(g$p, g$hardness),2)))+
  labs(title = "Hardness prediction",
       subtitle = "Comparing hardness artificial neural network regression and actual hardness",
       y = "HV hardness",
       x = "rank ordered by ascending hardness")+
  #annotate("text", y = 200, x = 25,label = paste("RMSE = ",
  #  round(RMSE(hard$hardness, dat$predictions),2)
  #))+
  theme_bw()+
  theme(legend.position = c(0.8,0.2),
        legend.background = element_rect(fill = "white", color = "black"))
  







```








