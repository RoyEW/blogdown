---
title: 'Metallurgical compositional analysis'
author: ''
date: '2020-07-03'
slug: compositional-analysis
categories: []
tags: []
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<pre class="r"><code>divide01 &lt;- function(x){
  return(x/100)
}

data &lt;- read.csv(&quot;hardness.csv&quot;) %&gt;% 
  mutate(Al=divide01(Al),
         Co=divide01(Co),
         Cr=divide01(Cr),
         Cu=divide01(Cu),
         Fe=divide01(Fe),
         Ni=divide01(Ni))
data_ordered &lt;- read.csv(&quot;hardness.csv&quot;) %&gt;% 
  mutate(Al=divide01(Al),
         Co=divide01(Co),
         Cr=divide01(Cr),
         Cu=divide01(Cu),
         Fe=divide01(Fe),
         Ni=divide01(Ni)) %&gt;% 
  arrange(desc(hardness))

closed &lt;- clo(data, parts = 1:6,total=100)
cx &lt;- acomp(data, c(&quot;Al&quot;,&quot;Co&quot;,&quot;Cr&quot;))
plot(cx)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>xc &lt;- acomp(data, c(&quot;Al&quot;,&quot;Co&quot;,&quot;Cr&quot;,&quot;Cu&quot;,&quot;Fe&quot;,&quot;Ni&quot;))
xc_ordered &lt;- acomp(data_ordered, c(&quot;Al&quot;,&quot;Co&quot;,&quot;Cr&quot;,&quot;Cu&quot;,&quot;Fe&quot;,&quot;Ni&quot;))
plot(xc)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<pre class="r"><code>barplot.acomp(xc)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-3.png" width="672" /></p>
<p>Order of hardness desc</p>
<pre class="r"><code>barplot.acomp(xc_ordered)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Possibly drop copper and nickel</p>
<pre class="r"><code>library(httr)
raw_dd &lt;- read.table(text=content(GET(&quot;https://gist.githubusercontent.com/MrFlick/c1183c911bc5398105d4/raw/715868fba2d0d17a61a8081de17c468bbc525ab1/elements.txt&quot;)), sep=&quot;,&quot;, header=TRUE) %&gt;%
  mutate(ElementName=ifelse(ElementName==&quot;Sulfer&quot;,&quot;Sulfur&quot;,ElementName),
         ElementName=ifelse(ElementName==&quot;Phosphorous&quot;,&quot;Phosphorus&quot;,ElementName),
         ElementName=ifelse(ElementName==&quot;Flourine&quot;,&quot;Fluorine&quot;,ElementName))
data &lt;- read_xlsx(&quot;melting_points.xlsx&quot;, sheet = &#39;Sheet2&#39;)
colnames(raw_dd) &lt;- c(colnames(raw_dd)[1:7],&quot;element&quot;,colnames(raw_dd)[9:13])</code></pre>
<pre class="r"><code>dd &lt;- raw_dd %&gt;%
  left_join(data, by = &quot;element&quot;) %&gt;%
  mutate(CTE_ppm=CTE*1000000,
         CTE_ppm=as.numeric(CTE_ppm),
         scaled_cte=CTE_ppm,
         scaled_cte=ifelse(scaled_cte&gt;8,8,scaled_cte),
         scaled_cte=ifelse(scaled_cte&lt;4.5,4.4,scaled_cte),
         new_structure=ifelse(crystal_structure %in% c(&quot;Body-centered Cubic&quot;,&quot;Face-centered Cubic&quot;,&quot;Simple Hexagonal&quot;),crystal_structure,NA))</code></pre>
<pre class="r"><code>dd %&gt;%
  ggplot(aes(Column,-Row)) +
  geom_tile(aes(fill=crystal_structure), color=&quot;black&quot;) +
  geom_text(aes(Column, -Row,label= symbol))+
  theme_void()+
  labs(
    fill = &quot;Crystal Structure&quot;
  ) +
  annotate(&quot;text&quot;, x = 7, y = 0.2, label = &quot;Periodic Table of the elements&quot;, size = 5)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>(p&lt;-dd %&gt;%
  filter(!is.na(symbol)) %&gt;%
  #filter(!crystal_structure %in% c(&quot;Base-centered Monoclinic&quot;,&quot;Centered Tetragonal&quot;)) %&gt;%
  ggplot(aes(Column, -Row))+
  geom_tile(aes(fill=scaled_cte), color=&quot;black&quot;,size=1) +
  geom_rect(aes(xmin=Column-0.3,xmax=Column+0.3,ymin=-Row-0.2,ymax=-Row+0.3,colour=new_structure),size=1,lty=1,fill=&quot;black&quot;)+
    #geom_text(aes(label=&quot;&quot;,colour=new_structure), na.rm = T,size=12,nudge_y = 0.3)+
  geom_text(aes(label=symbol),colour=&quot;yellow&quot;,nudge_y = +0.05)+
  geom_text(aes(label=CTE_ppm),colour=&quot;black&quot;,nudge_y = -0.35)+
  scale_fill_gradient(low = &quot;red&quot;,high = &quot;green&quot;)+
  labs(fill = expression(paste(&quot;CTE&quot;, 10^6)),
    colour=&quot;&quot;) +
  annotate(&quot;text&quot;, x = 7, y = 0.2, label = &quot;Periodic Table of the elements&quot;, size = 5))+
  theme_void()+
  theme(legend.position=&quot;bottom&quot;)+
  scale_colour_discrete(na.translate = F)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>f1 &lt;- function(x){
  return(1/(16.6*3*(x+273)))
}

library(plotly)
library(ggrepel)
data %&gt;% 
  ggplot(aes(mp, CTE, label=element))+
  geom_point()+
  stat_function(fun=f1)+
  lims(
    x=c(1500,4000),
    y=c(0,0.000025)
  )+
  theme(legend.position = &quot;none&quot;)+
  ggrepel::geom_text_repel()+
  theme_classic()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div id="predictive-modelling" class="section level1">
<h1>Predictive modelling</h1>
<p>Compositional data can be transformed to satisfy linearity by using logratio transformations for representation in a Euclidean space. Additive, isometric, and centre logratio transformations are available.</p>
<p>The transformations give the same coefficients for the multi-variate regressions so we will stick with the additive logratio defined as: <span class="math display">\[alr(x) = \left [\log\frac{x_1}{x_n},\ldots,\log\frac{x_{n-1}}{x_n}\right]\]</span></p>
<p>These transformation functions are available within the ‘compositions’ R package. Ratio transformations have issues with zero-value elements.</p>
<p>PRINCIPLES OF COMPOSITIONAL DATA ANALYSIS
BY JOHN AITCHISON</p>
<pre class="r"><code>library(compositions)

library(caret)

library(glmnet)
hard &lt;- read_csv(&quot;hardness.csv&quot;)
#hard %&gt;% arrange(-hardness)</code></pre>
<pre class="r"><code># Filtering out zero values for logratio transformations
hard_ &lt;- hard %&gt;% 
  #filter(Al &gt; 0, Co &gt; 0, Cr &gt; 0, Cu &gt; 0, Fe &gt; 0, Ni &gt; 0)
   mutate(Al = ifelse(Al == 0, 1, Al),
          Co = ifelse(Co == 0, 1, Co),
          Cr = ifelse(Cr == 0, 1, Cr),
          Cu = ifelse(Cu == 0, 1, Cu),
          Fe = ifelse(Fe == 0, 1, Fe),
          Ni = ifelse(Ni == 0, 1, Ni))</code></pre>
<pre class="r"><code># Setting x, y


y &lt;- hard_$hardness
x &lt;- hard_[,1:ncol(hard)-1]</code></pre>
<pre class="r"><code>hard.clr &lt;- x %&gt;% 
  clr()
hard.ilr &lt;- x %&gt;% 
  ilr()
hard.alr &lt;- x %&gt;% 
  alr()</code></pre>
<pre class="r"><code>#predict(hard.clr.lm,clr(v))

hard.clr.lm &lt;- lm(y ~ ., cbind(y,hard.clr) %&gt;% data.frame())
hard.ilr.lm &lt;- lm(y ~ ., cbind(y,hard.ilr) %&gt;% data.frame())
hard.alr.lm &lt;- lm(y ~ ., cbind(y,hard.alr) %&gt;% data.frame())</code></pre>
<pre class="r"><code>hard.ilr.glm.model &lt;- cv.glmnet(hard.ilr, y, alpha = 1)
hard.ilr.glm &lt;- glmnet(hard.ilr, y, alpha = 1, lambda = hard.ilr.glm.model$lambda.min)</code></pre>
<pre class="r"><code>dataset &lt;- cbind(data.frame(hardness = y),hard.clr) %&gt;% data.frame()

hard.clr.gam &lt;- gam(hardness ~ Al+ Co + Co + Cr + Cu + Fe + Ni, data = dataset)</code></pre>
<pre class="r"><code>predictions.full &lt;- data.frame(hard_) %&gt;% 
  mutate(prediction.clr.lm = predict(hard.clr.lm, newx = hard_),
         prediction.ilr.lm = predict(hard.ilr.lm, newx = hard.ilr),
         #prediction.alr.lm = predict(hard.alr.lm, newx = hard.alr),
         prediction.ilr.glm = predict(hard.ilr.glm, best_lambda = hard.ilr.glm.model$lambda.min, newx = hard.ilr),
         prediction.clr.gam = predict(hard.clr.gam, newx = hard.clr),
         pre = predict(hard.clr.lm, newx = row()))</code></pre>
<pre class="r"><code># predictions.full %&gt;% colnames

predictions.full %&gt;% 
  arrange(hardness) %&gt;% 
  mutate(row_name = row_number()) %&gt;% 
  pivot_longer(c(hardness, prediction.clr.lm,prediction.ilr.glm, prediction.clr.gam), names_to = &quot;variable&quot;,values_to = &quot;value&quot;) %&gt;% 
  ggplot(aes(row_name, value, colour = variable, shape = variable))+
  geom_point(alpha = 0.8)+
  labs(title = &quot;Hardness prediction&quot;,
       subtitle = &quot;Comparing hardness prediction.clr.lm and actual hardness&quot;,
       y = &quot;hardness&quot;,
       x = &quot;rank ordered by ascending hardness&quot;)+
  #annotate(&quot;text&quot;, y = 200, x = 25,label = paste(&quot;RMSE = &quot;,
   # round(RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness),2)
  #))+
  theme_bw()+
  theme(legend.position = c(0.8,0.2),
        legend.background = element_rect(fill = &quot;white&quot;, color = &quot;black&quot;))+
  scale_color_discrete(name = paste(&quot;RMSE = &quot;, round(RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness),2)))+
  scale_shape_discrete(name = paste(&quot;RMSE = &quot;, round(RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness),2)))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code># Linear regression on ILR logratio transformation  
RMSE(predictions.full$prediction.clr.lm, predictions.full$hardness)</code></pre>
<pre><code>## [1] 87.3938</code></pre>
<pre class="r"><code># Lasso regression on ILR logratio transformation
RMSE(predictions.full$prediction.ilr.glm, predictions.full$hardness)</code></pre>
<pre><code>## [1] 87.44176</code></pre>
<pre class="r"><code># generalised additive model
RMSE(predictions.full$prediction.clr.gam, predictions.full$hardness)</code></pre>
<pre><code>## [1] 87.3938</code></pre>
<pre class="r"><code># library(robCompositions)
# aDist(x = hard_[,1:ncol(hard)-1])
#Compositional::alfa.ridge(as.matrix(y), as.matrix(x),a = 0.01, lambda = 1)</code></pre>
</div>
<div id="principal-component-analysis-for-compositional-data-vectors" class="section level1">
<h1>Principal component analysis for compositional data vectors</h1>
<p><a href="https://link.springer.com/article/10.1007/s00180-015-0570-1" class="uri">https://link.springer.com/article/10.1007/s00180-015-0570-1</a></p>
</div>
<div id="artificial-neural-network-ann-approach" class="section level1">
<h1>Artificial Neural Network (ANN) approach</h1>
<pre class="r"><code>scale01 &lt;- function(x){
  (x - min(x)) / (max(x) - min(x))
}


scale02 &lt;- function(y){
  y * (max(hard_$hardness) - min(hard_$hardness)) + min(hard_$hardness)
}



hard_ann &lt;- cbind(hard_$hardness,as.tibble(hard.clr)) %&gt;% 
  mutate_all(scale01) %&gt;% rename(&quot;hardness&quot; = &quot;hard_$hardness&quot;)


set.seed(123)
hard_ann_train &lt;- sample_frac(tbl = hard_ann, replace = FALSE, size = 0.80)
hard_ann_test &lt;- anti_join(hard_ann, hard_ann_train)</code></pre>
<pre class="r"><code>hard_ann_model1 &lt;- neuralnet(hardness ~ Al + Co + 
                         Cr + Cu + Fe +
                         Ni, data = hard_ann_train)</code></pre>
<pre class="r"><code>hard_ann_model2 &lt;- neuralnet(hardness ~ Al + Co + 
                         Cr + Cu + Fe +
                         Ni, data = hard_ann_train,
                         hidden = c(4, 1), 
                         act.fct = &#39;logistic&#39;,
                         rep = 10)</code></pre>
<pre class="r"><code>hard_ann_test_output1 &lt;- compute(hard_ann_model1, hard_ann_test[, 2:7])$net.result
hard_ann_test_output2 &lt;- compute(hard_ann_model2, hard_ann_test[, 2:7])$net.result


hard_ann_sse1 &lt;- sum((hard_ann_test_output1 - hard_ann_test[, 1])^2)/2
hard_ann_sse2 &lt;- sum((hard_ann_test_output2 - hard_ann_test[, 1])^2)/2


hard_ann_sse1</code></pre>
<pre><code>## [1] 0.1559645</code></pre>
<pre class="r"><code>hard_ann_sse2 # model 2 is more accurate</code></pre>
<pre><code>## [1] 0.1558748</code></pre>
<pre class="r"><code>dat &lt;- cbind(p = hard_ann_test_output2, hard_ann_test) %&gt;%
  arrange(hardness) %&gt;%
  mutate(row = row_number()) %&gt;% 
  mutate(prediction = scale02(p),
         hardness = scale02(hardness))


dat</code></pre>
<pre><code>##             p hardness          Al          Co          Cr           Cu
## 1  0.08025127      110 0.459383079 0.822207735 0.674673178 0.0268815946
## 2  0.08225840      153 0.028256877 0.830248992 0.357670890 0.9202565621
## 3  0.08122400      157 0.008654047 0.720523903 0.591235196 0.7986361393
## 4  0.05125158      168 0.437042556 0.799088811 0.655702647 0.0314371313
## 5  0.06492592      170 0.091751450 0.939381313 0.770821471 0.1046872672
## 6  0.08289677      171 0.001464359 0.774618372 0.635623112 0.8585950083
## 7  0.18531365      207 0.471148738 0.660194372 0.541731021 0.7317662643
## 8  0.36297614      290 0.629478674 0.013659784 0.604838861 0.8170118686
## 9  0.40227888      315 0.655852328 0.011723956 0.599664076 0.8100218085
## 10 0.45400940      338 0.665032372 0.774900154 0.635854332 0.0019831455
## 11 0.43288219      339 0.679843819 0.010339998 0.594879031 0.8035582045
## 12 0.53028570      370 0.718614305 0.002246823 0.606999183 0.8199300158
## 13 0.56587768      418 0.641344621 0.660194372 0.541731021 0.7317662643
## 14 0.64710868      423 0.641344621 0.660194372 0.541731021 0.7317662643
## 15 0.68785006      430 0.876433709 0.902192960 0.072700350 0.0982030962
## 16 0.68833110      479 0.771742101 0.747683865 0.613521654 0.0008959313
## 17 0.78668798      482 0.849937686 0.726024390 0.595748692 0.0077060817
## 18 0.67092907      545 0.768211123 0.615591497 0.005922995 0.8765193696
## 19 0.55904764      546 0.779477613 0.008771169 0.574314370 0.7757796123
## 20 0.78296022      548 0.773580528 0.796316823 0.653428056 0.0103665837
## 21 0.58569235      550 0.806543872 0.435884783 0.681271536 0.0322407460
## 22 0.70816058      558 0.733559049 0.606169810 0.497400469 0.6718848818
## 23 0.69315897      587 0.773580528 0.796316823 0.653428056 0.0103665837
## 24 0.56432395      601 0.625079139 0.643450831 0.611672335 0.5173335157
## 25 0.75574472      603 0.783341307 0.595920729 0.488990452 0.6605246940
## 26 0.77001926      625 0.800775038 0.592331504 0.486045267 0.6565463598
## 27 0.78803216      655 0.823998848 0.587550228 0.482121929 0.6512467439
## 28 0.81933605      694 0.895080046 0.466733048 0.528200371 0.5173317332
## 29 0.91444580      695 0.822697893 0.919907330 0.754841843 0.0994068613
## 30 0.84721112      701 0.907235679 0.758112256 0.393251453 0.5312011598
## 31 0.79839193      735 0.837773718 0.584714282 0.479794858 0.6481033527
##           Fe         Ni row prediction
## 1  0.7453117 0.75097212   1   163.3671
## 2  0.7526009 0.75838174   2   164.7018
## 3  0.8112636 0.65727555   3   164.0140
## 4  0.7748289 0.78097684   4   144.0823
## 5  0.8515268 0.71109197   5   153.1757
## 6  0.6218311 0.70712090   6   165.1264
## 7  0.5984505 0.60168490   7   233.2336
## 8  0.6681657 0.83465256   8   351.3791
## 9  0.6624491 0.82885311   9   377.5155
## 10 0.7024285 0.70738055  10   411.9162
## 11 0.6571631 0.82349174  11   397.8667
## 12 0.6705522 0.75334321  12   462.6400
## 13 0.4396376 0.60168490  13   486.3087
## 14 0.5984505 0.44024860  14   540.3273
## 15 0.8178164 0.82467451  15   567.4203
## 16 0.6777576 0.68230210  16   567.7402
## 17 0.6581238 0.66234397  17   633.1475
## 18 0.7168319 0.72202188  18   556.1678
## 19 0.6344453 0.79971063  19   481.7667
## 20 0.7218422 0.53824657  20   630.6685
## 21 0.7526009 0.75838174  21   499.4854
## 22 0.5494785 0.55190397  22   580.9268
## 23 0.5360430 0.72711494  23   570.9507
## 24 0.5832728 0.58625657  24   485.2754
## 25 0.5401879 0.54245995  25   612.5702
## 26 0.5369344 0.53915266  26   622.0628
## 27 0.5326003 0.53474695  27   634.0414
## 28 0.5835032 0.58649068  28   654.8585
## 29 0.8338741 0.07598826  29   718.1065
## 30 0.4344250 0.59802069  30   673.3954
## 31 0.5300296 0.53213377  31   640.9306</code></pre>
<pre class="r"><code>dat %&gt;% 
  pivot_longer(c(&quot;prediction&quot;,&quot;hardness&quot;)) %&gt;% 
  mutate(row = as.integer((row_number()-1)/2)) %&gt;% 
  ggplot(aes(row, value, colour = name, shape = name)) + 
  geom_point()+
  scale_color_discrete(name = paste(&quot;RMSE = &quot;, round(RMSE(dat$prediction,dat$hardness),2)))+
  scale_shape_discrete(name = paste(&quot;RMSE = &quot;, round(RMSE(dat$prediction,dat$hardness),2)))+
  labs(title = &quot;Unseen data observations ANN&quot;,
       subtitle = &quot;Comparing hardness artificial neural network regression and actual hardness on unseen data&quot;)+
  theme_bw()+
  theme(legend.position = c(0.8,0.2),
        legend.background = element_rect(fill = &quot;white&quot;, color = &quot;black&quot;))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>hard_ann_results &lt;- compute(hard_ann_model2, hard_ann[, 2:7])$net.result</code></pre>
<pre class="r"><code>dat &lt;- cbind(predictions = hard_ann_results, hard_ann) %&gt;% 
  mutate(&quot;ANN prediction&quot; = scale02(predictions),
         hardness = scale02(hardness)) %&gt;% 
  arrange(hardness) %&gt;% 
  pivot_longer(c(&quot;ANN prediction&quot;,&quot;hardness&quot;), values_to = &quot;val&quot;, names_to = &quot;var&quot;) %&gt;% 
  mutate(row = as.integer((row_number()-1)/2))




g &lt;- cbind(data.frame(p = hard_ann_results) %&gt;% mutate(p = scale02(p)),hard_ann) %&gt;% 
  mutate(hardness = scale02(hardness))

dat %&gt;% 
  ggplot(aes(row, val, shape = var, colour = var)) +
  geom_point()+
  scale_color_discrete(type = c(&quot;dodgerblue&quot;, &quot;red&quot;),name = paste(&quot;RMSE = &quot;,round(RMSE(g$p, g$hardness),2)))+
  scale_shape_discrete(name = paste(&quot;RMSE = &quot;,round(RMSE(g$p, g$hardness),2)))+
  labs(title = &quot;Hardness prediction&quot;,
       subtitle = &quot;Comparing hardness artificial neural network regression and actual hardness&quot;,
       y = &quot;HV hardness&quot;,
       x = &quot;rank ordered by ascending hardness&quot;)+
  #annotate(&quot;text&quot;, y = 200, x = 25,label = paste(&quot;RMSE = &quot;,
  #  round(RMSE(hard$hardness, dat$predictions),2)
  #))+
  theme_bw()+
  theme(legend.position = c(0.8,0.2),
        legend.background = element_rect(fill = &quot;white&quot;, color = &quot;black&quot;))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
</div>
